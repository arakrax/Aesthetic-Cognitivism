{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f94b1b6",
   "metadata": {},
   "source": [
    "### Project Gutenberg dictionary\n",
    "Now we want to build a dictionary based on English books between 1600 - 1950 from the Project Gutenberg corpus. The idea is to create an era specific frequency dictionary to enhance the word correction in the pre-processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f8f816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from datasets import load_dataset\n",
    "import os # To get the number of CPU cores\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import pickle\n",
    "from functools import partial\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10bbc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This regex will extract words, including those with apostrophes (e.g., \"don't\", \"artist's\").\n",
    "# It excludes standalone punctuation and numbers mixed with symbols.\n",
    "WORD_REGEX = re.compile(r\"\\b[a-z0-9]+\\b\")\n",
    "POSSESSIVE_REGEX = re.compile(r\"'s\\b\")\n",
    "\n",
    "GP_DIR = \"./Data_project_gutenberg/\"\n",
    "DICTIONARY_DATA_DIR = './Dictionary_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48a5b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(directory_path, file_extension=\"csv\"):\n",
    "    \"\"\"\n",
    "    Return a list of files matching the given extension in directory_path.\n",
    "    Exits if no files are found.\n",
    "    \"\"\"\n",
    "    \n",
    "    file_pattern = os.path.join(directory_path, \"*.\" + file_extension) # e.g., './Data/*.csv'\n",
    "\n",
    "    print(f\"Finding all files matching: {file_pattern}\")\n",
    "    all_files = glob.glob(file_pattern, recursive=True)\n",
    "    print(f\"Found {len(all_files)} files to process.\")\n",
    "\n",
    "    if not all_files:\n",
    "        print(f\"Error: No files found. Check your DATA_DIR_PATH ({directory_path}) and file extension ({file_extension}).\")\n",
    "        exit() # Exit the script if no files are found\n",
    "    \n",
    "    return all_files, len(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09978535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_upper(text):\n",
    "    \"\"\"\n",
    "    Convert value to string and uppercase it.\n",
    "    Simpler and more robust than character-by-character handling.\n",
    "    Accepts None and other non-str inputs without error.\n",
    "    \"\"\"\n",
    "    result = \"\"   \n",
    "    for c in str(text):\n",
    "        if c.islower():\n",
    "            result += c.upper()\n",
    "        else:\n",
    "            result += c\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db97e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_project_gutenberg_book(file_path=None, title=None, author=None, language=None):\n",
    "    with open(file_path, 'r') as file_content:\n",
    "        start_saving    = False\n",
    "        saved_text      = list()\n",
    "        found_title     = None\n",
    "        found_author    = \"\"\n",
    "        found_language  = \"\"\n",
    "        for line in file_content:\n",
    "            clean_line = line.strip()\n",
    "            if clean_line:\n",
    "                if clean_line.startswith(\"*** END OF THE PROJECT GUTENBERG EBOOK\"):\n",
    "                    break\n",
    "\n",
    "                split_line = clean_line.split()\n",
    "\n",
    "                if split_line[0] == 'Title:':\n",
    "                    offset = len('Title:')\n",
    "                    found_title = clean_line[offset:].strip()\n",
    "                    if title and found_title not in title:\n",
    "                        return None, None, None, None\n",
    "                    continue\n",
    "\n",
    "                if split_line[0] == 'Author:':\n",
    "                    offset = len('Author:')\n",
    "                    found_author = clean_line[offset:].strip()\n",
    "                    if author and found_author not in author:\n",
    "                        return None, None, None, None\n",
    "                    continue\n",
    "\n",
    "                if split_line[0] == 'Language:':\n",
    "                    offset = len('Language:')\n",
    "                    found_language = clean_line[offset:].strip()\n",
    "                    if language and found_language not in language:\n",
    "                        return None, None, None, None\n",
    "                    continue\n",
    "\n",
    "                if found_title and clean_line == found_title.upper():\n",
    "                    start_saving = True\n",
    "                    continue\n",
    "\n",
    "                if start_saving:\n",
    "                    saved_text.append(clean_line)\n",
    "                    saved_text.append(\" \")\n",
    "\n",
    "            else:\n",
    "                if start_saving:\n",
    "                    saved_text.append(\"\\n\")\n",
    "        return found_title, found_author, found_language, \"\".join(saved_text)\n",
    "                \n",
    "    print(f\"Title: {found_title}\")\n",
    "    print(f\"Author: {found_author}\")\n",
    "    print(f\"Language: {found_language}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b571a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_word_counter(file_batch=None, pg_args=dict()):\n",
    "    # ... (same setup as before)\n",
    "    _, _, _, text = read_project_gutenberg_book(file_path=file_batch, \n",
    "                                                title=pg_args.get('title'), \n",
    "                                                author=pg_args.get('author'), \n",
    "                                                language=pg_args.get('language'))\n",
    "    \n",
    "    unigram_counter = Counter()\n",
    "    bigram_counter = Counter()\n",
    "\n",
    "    if isinstance(text, str):\n",
    "        # 1. Standardize and find all words\n",
    "        text = re.sub(r\"'s\\b\", \"\", text.lower())\n",
    "        words = re.findall(r\"\\b[a-z0-9]+\\b\", text)\n",
    "        \n",
    "        # 2. Update Unigrams (standard word counts)\n",
    "        unigram_counter.update(words)\n",
    "        \n",
    "        # 3. Create and update Bigrams (pairs of words)\n",
    "        # Zip the words list with itself shifted by one to get (w1, w2) pairs\n",
    "        if len(words) > 1:\n",
    "            bigrams = [f\"{words[i]} {words[i+1]}\" for i in range(len(words)-1)]\n",
    "            bigram_counter.update(bigrams)\n",
    "            \n",
    "    # Return both counters as a tuple\n",
    "    return (unigram_counter, bigram_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c8575f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def driver_GP_frequency_builder(data_dir_path=None, file_extension=\"txt\", batch_size=50, PG_args=None):\n",
    "    all_files, file_count = get_file_list(data_dir_path, file_extension=file_extension)\n",
    "    \n",
    "    num_cores = max(1, os.cpu_count() - 2) \n",
    "    final_unigrams = Counter()\n",
    "    final_bigrams = Counter()\n",
    "    partial_worker = partial(worker_word_counter, pg_args=PG_args)\n",
    "\n",
    "    print(f\"Starting processing pool with {num_cores} workers...\")\n",
    "\n",
    "    with multiprocessing.Pool(processes=num_cores) as pool:\n",
    "        # Using a larger chunksize for efficiency with many small files\n",
    "        results = pool.imap_unordered(partial_worker, all_files, chunksize=batch_size)\n",
    "        \n",
    "        with tqdm(total=file_count, desc=\"Processing files\") as pbar:\n",
    "            for unigrams, bigrams in results:\n",
    "                if unigrams:\n",
    "                    final_unigrams.update(unigrams)\n",
    "                if bigrams:\n",
    "                    final_bigrams.update(bigrams)\n",
    "                pbar.update(1)\n",
    "            \n",
    "        print(\"...Processing complete.\")\n",
    "\n",
    "    return final_unigrams, final_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "590a2082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding all files matching: ./Data_project_gutenberg/*/*.txt\n",
      "Found 75598 files to process.\n",
      "Starting processing pool with 4 workers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 75598/75598 [09:45<00:00, 129.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Processing complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "unigram_counts, bigram_counts = driver_GP_frequency_builder(\n",
    "    data_dir_path=GP_DIR + \"*\", \n",
    "    file_extension=\"txt\", \n",
    "    PG_args={\"language\": \"English\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7639d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 69939084),\n",
       " ('of', 36367417),\n",
       " ('and', 34771680),\n",
       " ('to', 28947276),\n",
       " ('a', 24076281),\n",
       " ('in', 19593482),\n",
       " ('i', 13693634),\n",
       " ('that', 13329369),\n",
       " ('he', 13146077),\n",
       " ('was', 12606378),\n",
       " ('it', 12272177),\n",
       " ('his', 9718397),\n",
       " ('is', 8591193),\n",
       " ('with', 8572143),\n",
       " ('for', 8433910),\n",
       " ('as', 8381070),\n",
       " ('you', 8351348),\n",
       " ('had', 7554995),\n",
       " ('her', 6811634),\n",
       " ('on', 6424446),\n",
       " ('but', 6408171),\n",
       " ('at', 6394728),\n",
       " ('not', 6293547),\n",
       " ('she', 6199784),\n",
       " ('be', 6098392),\n",
       " ('by', 5279325),\n",
       " ('have', 4840001),\n",
       " ('they', 4766184),\n",
       " ('this', 4668595),\n",
       " ('from', 4596890),\n",
       " ('which', 4565175),\n",
       " ('him', 4442740),\n",
       " ('all', 4329706),\n",
       " ('were', 3977033),\n",
       " ('one', 3893614),\n",
       " ('we', 3801237),\n",
       " ('or', 3628079),\n",
       " ('are', 3602511),\n",
       " ('so', 3584900),\n",
       " ('there', 3524106),\n",
       " ('my', 3447950),\n",
       " ('an', 3410976),\n",
       " ('said', 3284459),\n",
       " ('me', 3237021),\n",
       " ('no', 3105253),\n",
       " ('their', 3010266),\n",
       " ('when', 2963006),\n",
       " ('t', 2956252),\n",
       " ('if', 2904478),\n",
       " ('would', 2881075),\n",
       " ('been', 2806384),\n",
       " ('who', 2734310),\n",
       " ('what', 2707250),\n",
       " ('them', 2687079),\n",
       " ('out', 2535441),\n",
       " ('up', 2460090),\n",
       " ('will', 2344401),\n",
       " ('then', 2199258),\n",
       " ('more', 2149529),\n",
       " ('into', 2079516),\n",
       " ('do', 2065842),\n",
       " ('man', 1998281),\n",
       " ('could', 1944925),\n",
       " ('s', 1931115),\n",
       " ('now', 1898654),\n",
       " ('some', 1864183),\n",
       " ('has', 1858281),\n",
       " ('about', 1813107),\n",
       " ('time', 1789567),\n",
       " ('very', 1775439),\n",
       " ('little', 1756322),\n",
       " ('like', 1753231),\n",
       " ('can', 1679363),\n",
       " ('your', 1674880),\n",
       " ('only', 1673471),\n",
       " ('its', 1656303),\n",
       " ('than', 1644348),\n",
       " ('other', 1564453),\n",
       " ('did', 1520072),\n",
       " ('any', 1496972),\n",
       " ('two', 1477537),\n",
       " ('our', 1476439),\n",
       " ('over', 1451129),\n",
       " ('see', 1449159),\n",
       " ('well', 1439150),\n",
       " ('upon', 1421587),\n",
       " ('after', 1371079),\n",
       " ('down', 1366014),\n",
       " ('know', 1361599),\n",
       " ('made', 1355533),\n",
       " ('before', 1355518),\n",
       " ('these', 1323280),\n",
       " ('good', 1293758),\n",
       " ('great', 1283069),\n",
       " ('old', 1255032),\n",
       " ('may', 1247731),\n",
       " ('first', 1237167),\n",
       " ('such', 1221441),\n",
       " ('must', 1221147),\n",
       " ('should', 1213449),\n",
       " ('how', 1208020),\n",
       " ('day', 1207690),\n",
       " ('us', 1206971),\n",
       " ('come', 1195847),\n",
       " ('where', 1184617),\n",
       " ('much', 1175845),\n",
       " ('here', 1162550),\n",
       " ('way', 1146430),\n",
       " ('never', 1146204),\n",
       " ('back', 1138253),\n",
       " ('go', 1125496),\n",
       " ('men', 1125428),\n",
       " ('came', 1124928),\n",
       " ('mr', 1092078),\n",
       " ('long', 1060634),\n",
       " ('life', 1048471),\n",
       " ('through', 1022124),\n",
       " ('even', 1008467),\n",
       " ('again', 998193),\n",
       " ('own', 986398),\n",
       " ('too', 985648),\n",
       " ('just', 985347),\n",
       " ('most', 976298),\n",
       " ('don', 957535),\n",
       " ('say', 947400),\n",
       " ('himself', 935816),\n",
       " ('those', 929534),\n",
       " ('think', 923965),\n",
       " ('many', 921520),\n",
       " ('make', 916073),\n",
       " ('went', 885099),\n",
       " ('might', 879741),\n",
       " ('eyes', 878726),\n",
       " ('away', 868264),\n",
       " ('thought', 853697),\n",
       " ('while', 847527),\n",
       " ('still', 841277),\n",
       " ('being', 839900),\n",
       " ('every', 830207),\n",
       " ('new', 827493),\n",
       " ('hand', 819686),\n",
       " ('am', 816275),\n",
       " ('ll', 814344),\n",
       " ('take', 803831),\n",
       " ('get', 802580),\n",
       " ('without', 800600),\n",
       " ('last', 798739),\n",
       " ('house', 794969),\n",
       " ('people', 790253),\n",
       " ('m', 775191),\n",
       " ('place', 770432),\n",
       " ('found', 764179),\n",
       " ('under', 761934),\n",
       " ('same', 750004),\n",
       " ('face', 748590),\n",
       " ('right', 748014),\n",
       " ('though', 738252),\n",
       " ('off', 738207),\n",
       " ('yet', 734219),\n",
       " ('night', 732704),\n",
       " ('work', 731475),\n",
       " ('shall', 728485),\n",
       " ('once', 722602),\n",
       " ('d', 720374),\n",
       " ('another', 718541),\n",
       " ('nothing', 711510),\n",
       " ('head', 688612),\n",
       " ('three', 687982),\n",
       " ('young', 685857),\n",
       " ('let', 675855),\n",
       " ('years', 672725),\n",
       " ('room', 666679),\n",
       " ('why', 664759),\n",
       " ('left', 657257),\n",
       " ('tell', 654644),\n",
       " ('looked', 646147),\n",
       " ('things', 644930),\n",
       " ('ever', 643860),\n",
       " ('saw', 639945),\n",
       " ('world', 637574),\n",
       " ('always', 636081),\n",
       " ('going', 628854),\n",
       " ('because', 623909),\n",
       " ('also', 623059),\n",
       " ('mrs', 622438),\n",
       " ('father', 618257),\n",
       " ('look', 618220),\n",
       " ('put', 614280),\n",
       " ('got', 607808),\n",
       " ('far', 604591),\n",
       " ('each', 604176),\n",
       " ('against', 602062),\n",
       " ('few', 600414),\n",
       " ('asked', 596130),\n",
       " ('took', 595549),\n",
       " ('between', 592828),\n",
       " ('give', 592171),\n",
       " ('something', 589158),\n",
       " ('seemed', 583362),\n",
       " ('love', 576408)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_counts.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b8c7943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of the', 9660466),\n",
       " ('in the', 5494338),\n",
       " ('to the', 3727589),\n",
       " ('and the', 2624167),\n",
       " ('on the', 2398563),\n",
       " ('it was', 1927731),\n",
       " ('to be', 1900618),\n",
       " ('at the', 1722586),\n",
       " ('it is', 1670519),\n",
       " ('of a', 1628586),\n",
       " ('for the', 1596607),\n",
       " ('from the', 1524104),\n",
       " ('with the', 1455091),\n",
       " ('in a', 1420436),\n",
       " ('by the', 1395189),\n",
       " ('he was', 1367840),\n",
       " ('he had', 1297660),\n",
       " ('that the', 1246975),\n",
       " ('of his', 1223769),\n",
       " ('with a', 1195597),\n",
       " ('had been', 1055322),\n",
       " ('was a', 996505),\n",
       " ('that he', 919143),\n",
       " ('don t', 899085),\n",
       " ('and i', 846223),\n",
       " ('in his', 839217),\n",
       " ('into the', 816993),\n",
       " ('all the', 793271),\n",
       " ('for a', 790144),\n",
       " ('one of', 775847),\n",
       " ('i have', 766928),\n",
       " ('there was', 754192),\n",
       " ('as the', 745067),\n",
       " ('i am', 721040),\n",
       " ('have been', 719225),\n",
       " ('out of', 712113),\n",
       " ('as a', 711816),\n",
       " ('and a', 693940),\n",
       " ('the same', 693142),\n",
       " ('is a', 690806),\n",
       " ('did not', 677127),\n",
       " ('was the', 658313),\n",
       " ('is the', 655139),\n",
       " ('she was', 650203),\n",
       " ('and he', 636755),\n",
       " ('she had', 634960),\n",
       " ('that i', 605415),\n",
       " ('i was', 604362),\n",
       " ('the first', 594275),\n",
       " ('a little', 593164),\n",
       " ('he said', 586509),\n",
       " ('of her', 581705),\n",
       " ('they were', 580915),\n",
       " ('the other', 579525),\n",
       " ('as he', 577142),\n",
       " ('to a', 570345),\n",
       " ('and then', 551048),\n",
       " ('would be', 547682),\n",
       " ('but the', 547647),\n",
       " ('there is', 545911),\n",
       " ('was not', 539594),\n",
       " ('to his', 528769),\n",
       " ('i m', 512020),\n",
       " ('to have', 502575),\n",
       " ('but i', 485710),\n",
       " ('to her', 482730),\n",
       " ('and that', 474191),\n",
       " ('to do', 471066),\n",
       " ('of this', 469768),\n",
       " ('that it', 467495),\n",
       " ('i had', 466702),\n",
       " ('when the', 462115),\n",
       " ('and in', 454882),\n",
       " ('upon the', 453396),\n",
       " ('through the', 451452),\n",
       " ('to see', 451017),\n",
       " ('is not', 440715),\n",
       " ('if you', 439779),\n",
       " ('a man', 438470),\n",
       " ('to him', 433316),\n",
       " ('the old', 432043),\n",
       " ('and his', 430304),\n",
       " ('to me', 429781),\n",
       " ('a few', 426259),\n",
       " ('of it', 423925),\n",
       " ('could not', 423675),\n",
       " ('would have', 422503),\n",
       " ('in this', 419049),\n",
       " ('the most', 416670),\n",
       " ('over the', 416122),\n",
       " ('you are', 415919),\n",
       " ('when he', 413017),\n",
       " ('the world', 411917),\n",
       " ('will be', 411764),\n",
       " ('that she', 408293),\n",
       " ('to make', 403950),\n",
       " ('may be', 400292),\n",
       " ('of their', 397756),\n",
       " ('in her', 397561),\n",
       " ('by a', 393938),\n",
       " ('of them', 388936),\n",
       " ('they are', 385577),\n",
       " ('he is', 383691),\n",
       " ('i don', 375233),\n",
       " ('like a', 374607),\n",
       " ('that is', 374122),\n",
       " ('and it', 371034),\n",
       " ('such a', 370234),\n",
       " ('do you', 368676),\n",
       " ('i ll', 363789),\n",
       " ('he would', 362809),\n",
       " ('of course', 361868),\n",
       " ('i can', 359450),\n",
       " ('has been', 358413),\n",
       " ('more than', 355609),\n",
       " ('as if', 355463),\n",
       " ('and to', 354728),\n",
       " ('on a', 352019),\n",
       " ('his own', 350986),\n",
       " ('they had', 350524),\n",
       " ('who had', 348688),\n",
       " ('with his', 344817),\n",
       " ('him and', 344014),\n",
       " ('a great', 342206),\n",
       " ('which he', 341901),\n",
       " ('that they', 340734),\n",
       " ('in which', 339475),\n",
       " ('of all', 339052),\n",
       " ('the great', 338154),\n",
       " ('the whole', 335094),\n",
       " ('which the', 334313),\n",
       " ('he could', 334226),\n",
       " ('going to', 333259),\n",
       " ('him to', 332809),\n",
       " ('she said', 332365),\n",
       " ('as i', 330097),\n",
       " ('but he', 328181),\n",
       " ('the man', 328040),\n",
       " ('to go', 323750),\n",
       " ('but it', 320684),\n",
       " ('on his', 317761),\n",
       " ('if he', 317294),\n",
       " ('it would', 316539),\n",
       " ('do not', 316265),\n",
       " ('you have', 314980),\n",
       " ('must be', 314695),\n",
       " ('about the', 314108),\n",
       " ('the house', 313688),\n",
       " ('and she', 313071),\n",
       " ('up the', 310240),\n",
       " ('of my', 308150),\n",
       " ('of that', 306999),\n",
       " ('part of', 306732),\n",
       " ('as to', 306561),\n",
       " ('should be', 304714),\n",
       " ('the door', 304404),\n",
       " ('had a', 304261),\n",
       " ('if i', 303466),\n",
       " ('seemed to', 303208),\n",
       " ('be a', 303136),\n",
       " ('it and', 301246),\n",
       " ('didn t', 299567),\n",
       " ('you know', 299337),\n",
       " ('can t', 297117),\n",
       " ('under the', 296679),\n",
       " ('to say', 295807),\n",
       " ('was in', 294994),\n",
       " ('said the', 294688),\n",
       " ('a good', 294083),\n",
       " ('we have', 293637),\n",
       " ('had not', 292260),\n",
       " ('the time', 291900),\n",
       " ('i will', 289021),\n",
       " ('the two', 288766),\n",
       " ('to get', 288644),\n",
       " ('this is', 287617),\n",
       " ('that you', 287353),\n",
       " ('when i', 284340),\n",
       " ('that was', 281928),\n",
       " ('i think', 279460),\n",
       " ('the last', 278921),\n",
       " ('to take', 278430),\n",
       " ('as it', 278288),\n",
       " ('as she', 277848),\n",
       " ('as they', 277552),\n",
       " ('a very', 276705),\n",
       " ('was to', 276049),\n",
       " ('not to', 273615),\n",
       " ('the little', 272775),\n",
       " ('i ve', 271265),\n",
       " ('i know', 271086),\n",
       " ('the way', 270688),\n",
       " ('of which', 269942),\n",
       " ('you will', 267462),\n",
       " ('in their', 266441),\n",
       " ('of these', 265652),\n",
       " ('i could', 264715),\n",
       " ('up to', 261352),\n",
       " ('there are', 261020),\n",
       " ('and as', 260520)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_counts.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79581e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1337241 identified words with frequencies to: ./Dictionary_data/project_gutenberg_word_count.pkl\n"
     ]
    }
   ],
   "source": [
    "output_path = os.path.join(DICTIONARY_DATA_DIR, \"project_gutenberg_word_count.txt\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    # most_common() already returns (word, count) sorted desc by count\n",
    "    for word, count in unigram_counts.most_common():\n",
    "        f.write(f\"{word}\\t{count}\\n\")\n",
    "\n",
    "\n",
    "output_path = os.path.join(DICTIONARY_DATA_DIR, \"project_gutenberg_word_count.pkl\")\n",
    "with open(output_path, 'wb') as file:\n",
    "    pickle.dump(unigram_counts, file)\n",
    "print(f\"Saved {len(unigram_counts)} identified words with frequencies to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bce7568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Bigrams in SymSpell format\n",
    "output_path_bigrams = os.path.join(DICTIONARY_DATA_DIR, \"project_gutenberg_bigrams.txt\")\n",
    "with open(output_path_bigrams, \"w\", encoding=\"utf-8\") as f:\n",
    "    for bigram, count in bigram_counts.most_common():\n",
    "        # bigram is already \"word1 word2\"\n",
    "        f.write(f\"{bigram}\\t{count}\\n\")\n",
    "\n",
    "# Also save as pickle for fast loading in other scripts\n",
    "with open(os.path.join(DICTIONARY_DATA_DIR, \"project_gutenberg_bigrams.pkl\"), 'wb') as file:\n",
    "    pickle.dump(bigram_counts, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andreas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
