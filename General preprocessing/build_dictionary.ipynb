{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6feeb89",
   "metadata": {},
   "source": [
    "This notebook collects and consolidates multiple wordlists and named-entity sources into two pickled dictionaries:\n",
    "- `artist_wordlist.pkl` — words and names related to the art world (artists, institutions).\n",
    "- `ner_wordlist.pkl` — words extracted from NER-tagged corpora.\n",
    "\n",
    "Overview:\n",
    "1. Load multiple external sources (CSV, JSON, text files, HF datasets).\n",
    "2. Normalize entries (lowercasing, splitting multiword names where useful).\n",
    "3. Extract entities from NER-tagged datasets and other curated sources.\n",
    "4. Save consolidated sets to `Dictionary_data/` for use in downstream pipelines.\n",
    "\n",
    "Notes and usage:\n",
    "- Data sources are loaded from `DICTIONARY_DATA_DIR` — change that variable to point to your data folder.\n",
    "- The notebook favors conservative, rule-based extraction; inspect intermediate prints if any source contains unexpected formatting.\n",
    "- When adding new sources, follow existing patterns: load, normalize to lowercase with `to_lower()`, and `update()` the appropriate sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84edc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb25958",
   "metadata": {},
   "outputs": [],
   "source": [
    "DICTIONARY_DATA_DIR = 'Dictionary_data/'\n",
    "NER_DIR = DICTIONARY_DATA_DIR + 'ner_dictionary/'\n",
    "ARTWORLD_WORDLIST = set()\n",
    "NER_WORDLIST = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c9fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(file_name, pd_args=None):\n",
    "    \"\"\"\n",
    "    Attempt to read a CSV using several common encodings.\n",
    "    Returns a pandas DataFrame on success or raises ValueError.\n",
    "    pd_args can contain extra arguments to pass to pd.read_csv (e.g., on_bad_lines).\n",
    "    \"\"\"\n",
    "    encodings_to_try = ['utf-8', 'Latin-1', 'ISO-8859-1']\n",
    "    \n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            df = pd.read_csv(DICTIONARY_DATA_DIR + file_name, encoding=encoding, **(pd_args or {}))\n",
    "            print(\"File read successfully with encoding:\", encoding)\n",
    "            print(df.head()) # quick sanity-check to see columns and first rows\n",
    "            return df\n",
    "        except UnicodeDecodeError:\n",
    "            # try the next encoding\n",
    "            pass\n",
    "    raise ValueError(\"Failed to read the file with the provided encodings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdbe76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(word):\n",
    "    \"\"\"\n",
    "    Convert value to string and lowercase it.\n",
    "    Simpler and more robust than character-by-character handling.\n",
    "    Accepts None and other non-str inputs without error.\n",
    "    \"\"\"\n",
    "    result = \"\"\n",
    "    for c in str(word):\n",
    "        if c.isupper():\n",
    "            result += c.lower()\n",
    "        else:\n",
    "            result += c\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469e1a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read successfully with encoding: utf-8\n",
      "                                              Quotes      Writter name\n",
      "0  Reading Kafka I sense that the elicited questi...  Alberto Manguel,\n",
      "1  All animals are equal but some animals are mor...     George Orwell\n",
      "2  I am old Gandalf I dont look it but I am begin...    J.R.R. Tolkien\n",
      "3  How can we live without our lives How will we ...    John Steinbeck\n",
      "4  I was only foolin George I dont want no ketchu...    John Steinbeck\n",
      "83\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/rafsunahmad/popular-quotes-author-classifier?resource=download\n",
    "file_name = 'Autor_detection.csv'\n",
    "df_author = load_csv(file_name)\n",
    "writers = set(df_author.loc[:]['Writter name'].apply(lambda x: to_lower(x)))\n",
    "print(len(writers))\n",
    "ARTWORLD_WORDLIST.update(writers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc91d9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read successfully with encoding: utf-8\n",
      "     artist_name  edition_number  year artist_nationality  \\\n",
      "0  Aaron Douglas             9.0  1991           American   \n",
      "1  Aaron Douglas            10.0  1996           American   \n",
      "2  Aaron Douglas            11.0  2001           American   \n",
      "3  Aaron Douglas            12.0  2005           American   \n",
      "4  Aaron Douglas            13.0  2009           American   \n",
      "\n",
      "  artist_nationality_other artist_gender                artist_race  \\\n",
      "0                 American          Male  Black or African American   \n",
      "1                 American          Male  Black or African American   \n",
      "2                 American          Male  Black or African American   \n",
      "3                 American          Male  Black or African American   \n",
      "4                 American          Male  Black or African American   \n",
      "\n",
      "                artist_ethnicity     book  space_ratio_per_page_total  \\\n",
      "0  Not Hispanic or Latino origin  Gardner                    0.353366   \n",
      "1  Not Hispanic or Latino origin  Gardner                    0.373947   \n",
      "2  Not Hispanic or Latino origin  Gardner                    0.303259   \n",
      "3  Not Hispanic or Latino origin  Gardner                    0.377049   \n",
      "4  Not Hispanic or Latino origin  Gardner                    0.398410   \n",
      "\n",
      "   artist_unique_id  moma_count_to_year  whitney_count_to_year artist_race_nwi  \n",
      "0                 2                   0                      0       Non-White  \n",
      "1                 2                   0                      0       Non-White  \n",
      "2                 2                   0                      0       Non-White  \n",
      "3                 2                   0                      0       Non-White  \n",
      "4                 2                   0                      0       Non-White  \n",
      "413\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/joebeachcapital/art-history\n",
    "file_name = 'artists.csv'\n",
    "df_artists = load_csv(file_name)\n",
    "artists = set(df_artists.loc[:]['artist_name'].apply(lambda x: to_lower(x)))\n",
    "print(len(artists))\n",
    "ARTWORLD_WORDLIST.update(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce04f146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read successfully with encoding: utf-8\n",
      "                                               Title  \\\n",
      "0  Ferdinandsbrücke Project, Vienna, Austria, Ele...   \n",
      "1  City of Music, National Superior Conservatory ...   \n",
      "2  Villa near Vienna Project, Outside Vienna, Aus...   \n",
      "3  The Manhattan Transcripts Project, New York, N...   \n",
      "4  Villa, project, outside Vienna, Austria, Exter...   \n",
      "\n",
      "                     Artist ConstituentID  \\\n",
      "0               Otto Wagner          6210   \n",
      "1  Christian de Portzamparc          7470   \n",
      "2                Emil Hoppe          7605   \n",
      "3           Bernard Tschumi          7056   \n",
      "4                Emil Hoppe          7605   \n",
      "\n",
      "                                   ArtistBio Nationality BeginDate EndDate  \\\n",
      "0                      (Austrian, 1841–1918)  (Austrian)    (1841)  (1918)   \n",
      "1                        (French, born 1944)    (French)    (1944)     (0)   \n",
      "2                      (Austrian, 1876–1957)  (Austrian)    (1876)  (1957)   \n",
      "3  (French and Swiss, born Switzerland 1944)          ()    (1944)     (0)   \n",
      "4                      (Austrian, 1876–1957)  (Austrian)    (1876)  (1957)   \n",
      "\n",
      "   Gender  Date                                             Medium  ...  \\\n",
      "0  (Male)  1896      Ink and cut-and-pasted painted pages on paper  ...   \n",
      "1  (Male)  1987                  Paint and colored pencil on print  ...   \n",
      "2  (Male)  1903  Graphite, pen, color pencil, ink, and gouache ...  ...   \n",
      "3  (Male)  1980  Photographic reproduction with colored synthet...  ...   \n",
      "4  (Male)  1903  Graphite, color pencil, ink, and gouache on tr...  ...   \n",
      "\n",
      "                                        ThumbnailURL Circumference (cm)  \\\n",
      "0  http://www.moma.org/media/W1siZiIsIjU5NDA1Il0s...                NaN   \n",
      "1  http://www.moma.org/media/W1siZiIsIjk3Il0sWyJw...                NaN   \n",
      "2  http://www.moma.org/media/W1siZiIsIjk4Il0sWyJw...                NaN   \n",
      "3  http://www.moma.org/media/W1siZiIsIjEyNCJdLFsi...                NaN   \n",
      "4  http://www.moma.org/media/W1siZiIsIjEyNiJdLFsi...                NaN   \n",
      "\n",
      "  Depth (cm) Diameter (cm) Height (cm) Length (cm) Weight (kg)  Width (cm)  \\\n",
      "0        NaN           NaN     48.6000         NaN         NaN    168.9000   \n",
      "1        NaN           NaN     40.6401         NaN         NaN     29.8451   \n",
      "2        NaN           NaN     34.3000         NaN         NaN     31.8000   \n",
      "3        NaN           NaN     50.8000         NaN         NaN     50.8000   \n",
      "4        NaN           NaN     38.4000         NaN         NaN     19.1000   \n",
      "\n",
      "  Seat Height (cm) Duration (sec.)  \n",
      "0              NaN             NaN  \n",
      "1              NaN             NaN  \n",
      "2              NaN             NaN  \n",
      "3              NaN             NaN  \n",
      "4              NaN             NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "13861\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/rishidamarla/art-and-artists-from-the-museum-of-modern-art?select=Artworks.csv\n",
    "file_name = 'Artworks.csv'\n",
    "df_artworks = load_csv(file_name)\n",
    "artworks = set(df_artworks.loc[:]['Artist'].apply(lambda x: to_lower(x)))\n",
    "print(len(artworks))\n",
    "ARTWORLD_WORDLIST.update(artworks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cafaaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File read successfully with encoding: utf-8\n",
      "   ConstituentID      DisplayName            ArtistBio Nationality Gender  \\\n",
      "0              1   Robert Arneson  American, 1930–1992    American   Male   \n",
      "1              2   Doroteo Arnaiz   Spanish, born 1936     Spanish   Male   \n",
      "2              3      Bill Arnold  American, born 1941    American   Male   \n",
      "3              4  Charles Arnoldi  American, born 1946    American   Male   \n",
      "4              5      Per Arnoldi    Danish, born 1941      Danish   Male   \n",
      "\n",
      "   BeginDate  EndDate  Wiki QID         ULAN  \n",
      "0       1930     1992       NaN          NaN  \n",
      "1       1936        0       NaN          NaN  \n",
      "2       1941        0       NaN          NaN  \n",
      "3       1946        0  Q1063584  500027998.0  \n",
      "4       1941        0       NaN          NaN  \n",
      "15226\n"
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/mfrancis23/museum-of-modern-art-collection?select=Artists.csv\n",
    "file_name = 'Artists.csv'\n",
    "df_moma_artists = load_csv(file_name)\n",
    "moma_artists = set(df_moma_artists.loc[:]['DisplayName'].apply(lambda x: to_lower(x)))\n",
    "print(len(moma_artists))\n",
    "ARTWORLD_WORDLIST.update(moma_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a79b13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTLIST = list(ARTWORLD_WORDLIST)\n",
    "NEW_ARTLIST = ARTLIST.copy()\n",
    "for row in ARTLIST:\n",
    "    NEW_ARTLIST.extend(row.split())\n",
    "\n",
    "ARTWORLD_WORDLIST = set(NEW_ARTLIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16a9b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/thedevastator/ner-tagged-text-dataset\n",
    "\n",
    "def extract_entities_from_row(row):\n",
    "    \"\"\"\n",
    "    Parse token and ner_tags columns assumed to contain Python list literal strings.\n",
    "    Returns lowercased entity words where the corresponding tag != '0'.\n",
    "    \"\"\"\n",
    "    # Assuming 'tokens' and 'ner_tags' columns contain Python lists\n",
    "    words = [word.strip('[,],\\'') for word in row['tokens'].split()]\n",
    "    tags = [tag.strip('[,]') for tag in row['ner_tags'].split() if len(tag.strip('[,]')) > 0]\n",
    "\n",
    "    if len(words) != len(tags):\n",
    "        # Handle rows with length mismatch if necessary\n",
    "        print(1)\n",
    "        return []\n",
    "\n",
    "    # Use a generator for efficient extraction: only keep the word if the tag is not 0\n",
    "    entities = [to_lower(word) for word, tag in zip(words, tags) if tag != '0']\n",
    "    return entities\n",
    "\n",
    "\n",
    "filenames = ['test', 'train', 'validation']\n",
    "ner_tagged_text = set()\n",
    "\n",
    "for filename in filenames:\n",
    "    df = pd.read_csv(NER_DIR + 'archive/' + filename + '.csv')\n",
    "    \n",
    "    # --- Execution Steps ---\n",
    "    # 1. Apply the extraction function row-wise to get a list of entities for each row.\n",
    "    df['entities'] = df.apply(extract_entities_from_row, axis=1)\n",
    "    # 2. Flatten the resulting list of lists (the 'entities' column) into a single, long series.\n",
    "    # 3. Convert the series to a set to get all unique extracted words.\n",
    "    ner_tagged_text.update(set(df['entities'].explode().dropna()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932f01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/datasets/abhinavwalia95/entity-annotated-corpus?resource=download\n",
    "\n",
    "filename = 'ner.csv'\n",
    "found_entities = list()\n",
    "\n",
    "df = pd.read_csv(NER_DIR + filename, encoding='cp1252', on_bad_lines='skip')\n",
    "words = df['word']\n",
    "tags  = df['tag']\n",
    "\n",
    "for word, tag in zip(words, tags):\n",
    "    if tag in ['B-geo', 'B-org', 'I-per']:\n",
    "        found_entities.append(to_lower(word))\n",
    "\n",
    "found_entities = set(found_entities)\n",
    "NER_WORDLIST.update(found_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/datasets/Babelscape/wikineural\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Babelscape/wikineural\")\n",
    "\n",
    "multi_lang_set = set()\n",
    "# iterate over all splits and collect tokens with entity tags\n",
    "ds.get('test_en')['ner_tags']\n",
    "for dataset in ds.values():\n",
    "    words = ds.get('test_en')['tokens']\n",
    "    tags  = ds.get('test_en')['ner_tags']\n",
    "    for row_w, row_t in zip(words, tags):\n",
    "        for w, t in zip(row_w, row_t):\n",
    "            if 0 < t and t < 7:\n",
    "                multi_lang_set.add(to_lower(w))\n",
    "NER_WORDLIST.update(multi_lang_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e1226",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DICTIONARY_DATA_DIR + 'artist_wordlist.pkl', 'wb') as f:\n",
    "    pickle.dump(ARTWORLD_WORDLIST, f)\n",
    "    \n",
    "with open(DICTIONARY_DATA_DIR + 'ner_wordlist.pkl', 'wb') as f:\n",
    "    pickle.dump(NER_WORDLIST, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5f1ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words collected: 502183\n",
      "Art related words collected: 33188\n",
      "NER entity words collected: 14874\n"
     ]
    }
   ],
   "source": [
    "print(f\"Art related words collected: {len(ARTWORLD_WORDLIST)}\")\n",
    "print(f\"NER entity words collected: {len(NER_WORDLIST)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andreas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
