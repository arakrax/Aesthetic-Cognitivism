{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3af56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from spellchecker import SpellChecker\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "import difflib\n",
    "import re\n",
    "import torch\n",
    "import textwrap\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6cb35c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7ea9dedf5b462faf265280a96c3654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = 'Books_gale.csv'\n",
    "folder = './Data'\n",
    "dataset = load_dataset(\"csv\", data_files=folder + '/' + file, nrows=100)\n",
    "model_name = 'roBERTa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aded4c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Author', 'Title', 'Publication', 'Date', 'Place', 'Full_text', 'URL'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "257e9ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset['train']['Full_text'])  # Display the first record to understand its structure\n",
    "\n",
    "with open(\"books_text.txt\", \"a\") as f:\n",
    "    for text in dataset['train']['Full_text']:\n",
    "        f.write(\"\\n\\n--- START OF TEXT PIECE ---\\n\\n\")\n",
    "        f.write(text)\n",
    "        f.write(\"\\n\\n--- END OF TEXT PIECE ---\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f4f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define the Helper Functions for text cleaning ---\n",
    "def pre_clean_for_model(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Performs a hard scrub of the text to remove only the most severe OCR noise\n",
    "    before sending it to a language model.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.replace('\\n', ' ').replace('<NEWPAGE>', ' ')\n",
    "    text = re.sub(r'[^A-Za-z0-9\\s.,!?-]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464c224d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. The Final, Robust, Chunk-Based Correction Function FOR A SINGLE REVIEW ---\n",
    "def correct_review_with_mlm(review_text: str, nlp_pipeline, spell_checker, chunk_size, overlap, max_len=510):\n",
    "    \"\"\"\n",
    "    (FINAL ROBUST & RECOVERABLE VERSION)\n",
    "    Corrects a single review. Returns the corrected text on success, or None on failure.\n",
    "    \"\"\"\n",
    "    if not review_text or not review_text.strip():\n",
    "        return \"\"\n",
    "\n",
    "    words = review_text.split()\n",
    "    all_corrected_chunks = []\n",
    "    start = 0\n",
    "    has_failed = False  # Flag to track if any chunk fails\n",
    "\n",
    "    while start < len(words):\n",
    "        end = start + chunk_size\n",
    "        chunk_text = \" \".join(words[start:end])\n",
    "\n",
    "        try:\n",
    "            tokens = re.findall(r'\\w+|[^\\w\\s]', chunk_text)\n",
    "            unknown_words = spell_checker.unknown([token for token in tokens if token.isalpha()])\n",
    "            \n",
    "            if not unknown_words:\n",
    "                all_corrected_chunks.append(chunk_text)\n",
    "            else:\n",
    "                masked_sentences, correction_map = [], {}\n",
    "                for i, token in enumerate(tokens):\n",
    "                    if token in unknown_words:\n",
    "                        temp_tokens = list(tokens)\n",
    "                        temp_tokens[i] = nlp_pipeline.tokenizer.mask_token\n",
    "                        masked_text = nlp_pipeline.tokenizer.convert_tokens_to_string(temp_tokens)\n",
    "                        \n",
    "                        # --- DEFINITIVE SAFETY CHECK ---\n",
    "                        token_ids = nlp_pipeline.tokenizer(masked_text, truncation=False)['input_ids']\n",
    "                        if len(token_ids) > max_len:\n",
    "                            print(f\"WARNING: A masked sentence in a chunk was too long ({len(token_ids)} tokens). Skipping this specific correction.\")\n",
    "                            has_failed = True\n",
    "                            continue\n",
    "                        \n",
    "                        masked_sentences.append(masked_text)\n",
    "                        correction_map[len(masked_sentences) - 1] = i\n",
    "                \n",
    "                if masked_sentences:\n",
    "                    # The call for 'fill-mask' does NOT take 'truncation'.\n",
    "                    predictions = nlp_pipeline(masked_sentences)\n",
    "                    \n",
    "                    if isinstance(predictions[0], dict):\n",
    "                        predictions = [predictions]\n",
    "                    \n",
    "                    corrected_tokens = list(tokens)\n",
    "                    for i, pred_group in enumerate(predictions):\n",
    "                        token_idx_to_correct = correction_map[i]\n",
    "                        best_suggestion = None\n",
    "                        for pred in pred_group:\n",
    "                            suggestion = pred['token_str'].strip()\n",
    "                            if suggestion.isalpha() and len(suggestion) > 1:\n",
    "                                best_suggestion = suggestion\n",
    "                                break\n",
    "                        if best_suggestion:\n",
    "                            corrected_tokens[token_idx_to_correct] = best_suggestion\n",
    "                    \n",
    "                    # Reassemble tokens with spaces correctly\n",
    "                    reassembled_text = \" \".join(corrected_tokens)\n",
    "                    reassembled_text = re.sub(r'\\s([.,!?-])', r'\\1', reassembled_text)\n",
    "                    all_corrected_chunks.append(reassembled_text)\n",
    "                else:\n",
    "                     all_corrected_chunks.append(chunk_text)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: An error occurred on a chunk. Marking review as failed. Error: {e}\")\n",
    "            all_corrected_chunks.append(chunk_text) # Append original chunk on error\n",
    "            has_failed = True # Set the failure flag\n",
    "        finally:\n",
    "            start += chunk_size - overlap\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    # --- Propagate Failure Signal ---\n",
    "    if has_failed:\n",
    "        print(\"FAILED RETURNING NONE\")\n",
    "        return None \n",
    "\n",
    "    # --- Reassembly Logic ---\n",
    "    final_text_words = []\n",
    "    for i, chunk_text in enumerate(all_corrected_chunks):\n",
    "        chunk_words = chunk_text.split()\n",
    "        if i == 0:\n",
    "            final_text_words.extend(chunk_words)\n",
    "        else:\n",
    "            final_text_words.extend(chunk_words[overlap:])\n",
    "    \n",
    "    return \" \".join(final_text_words)\n",
    "\n",
    "# --- 3. The Main Mapping Function for .map() ---\n",
    "def apply_cleaning_in_batch(examples, nlp_pipeline, spell_checker, chunk_size=400, overlap=50):\n",
    "    \"\"\"Applies the robust, chunk-based correction to a batch of reviews.\"\"\"\n",
    "    pre_cleaned_texts = [pre_clean_for_model(text) for text in examples['Full_text']]\n",
    "    \n",
    "    final_cleaned_texts = []\n",
    "    for text in pre_cleaned_texts:\n",
    "        corrected_text = correct_review_with_mlm(text, nlp_pipeline, spell_checker, chunk_size, overlap)\n",
    "        if corrected_text is None:\n",
    "            # If the inner function signalled a failure, mark it for recovery.\n",
    "            final_cleaned_texts.append(\"__FAILED__\")\n",
    "        else:\n",
    "            final_cleaned_texts.append(corrected_text)\n",
    "            \n",
    "    return {'Cleaned_text': final_cleaned_texts}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2cef35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the text correction model (this may take a moment)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\n",
      "--- Applying the FINAL cleaning pipeline ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22653476b8934e20bcbf31df19bc9423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (701 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: A masked sentence in a chunk was too long (701 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (699 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (700 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (612 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (611 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (612 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (611 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (600 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (602 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (602 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (602 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (601 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (624 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (624 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (624 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (635 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (638 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (621 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (621 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (620 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (620 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (619 tokens). Skipping this specific correction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (594 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (633 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (656 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (656 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (631 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (676 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (675 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (676 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (677 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (676 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (675 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (676 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (675 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (608 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (606 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (606 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (608 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (608 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (607 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (608 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (599 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (598 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (599 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (598 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (599 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (598 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (598 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (598 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (649 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (651 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (649 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (645 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (643 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (643 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (644 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (620 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (617 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (620 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (620 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (619 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (597 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (597 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (598 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (598 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (598 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (597 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (554 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (553 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (551 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (555 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (553 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (554 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (577 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (576 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (576 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (576 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (575 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (577 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (575 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (624 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (647 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (648 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (646 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (648 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (647 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (648 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (648 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (609 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (609 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (610 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (609 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (619 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (618 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (619 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (620 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (620 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (619 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (618 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (582 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (567 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (567 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (568 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (567 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (568 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (582 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (582 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (587 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (587 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (586 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (586 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (587 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (592 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (592 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (592 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (633 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (631 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (633 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (634 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (648 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (651 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (652 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (651 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (651 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (651 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (651 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (618 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (618 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (616 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (602 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (602 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (603 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (597 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (645 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (646 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (645 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (646 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (645 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (646 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (629 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (631 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (630 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (629 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (629 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (593 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (594 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (594 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (594 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (616 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (617 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (621 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (621 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (619 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (621 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (638 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (638 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (635 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (635 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (517 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (517 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (518 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (520 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (518 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (518 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (519 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (520 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (520 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (520 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (519 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (520 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (518 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (519 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (519 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (520 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (519 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (625 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (625 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (626 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (635 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (635 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (652 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (649 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (649 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (653 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (653 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (653 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (631 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (631 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (641 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (642 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (656 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (653 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (651 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (656 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (656 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (663 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (665 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (665 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (665 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (664 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (638 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (616 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (616 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (647 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (647 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (647 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (647 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (644 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (643 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (644 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (644 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (646 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (647 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (646 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (645 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (560 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (563 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (563 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (580 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (581 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (580 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (580 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (571 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (571 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (572 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (572 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (572 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (572 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (570 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (537 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (536 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (636 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (635 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (616 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (616 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (616 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (577 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (577 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (579 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (578 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (578 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (578 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (621 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (631 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (633 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (631 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (631 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (631 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (593 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (592 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (592 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (593 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (593 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (603 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (603 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (605 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (603 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (605 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (605 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (603 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (726 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (725 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (724 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (726 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (723 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (725 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (725 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (725 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (725 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (726 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (719 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (724 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (726 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (725 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (664 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (666 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (665 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (666 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (665 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (665 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (666 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (656 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (656 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (657 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (657 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (658 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (659 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (658 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (656 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (658 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (657 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (658 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (658 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (672 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (673 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (673 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (675 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (673 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (617 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (618 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (617 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (617 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (511 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (511 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (511 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (649 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (651 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (648 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (648 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (647 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (651 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (651 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (650 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (673 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (670 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (673 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (673 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (672 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (673 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (619 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (618 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (616 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (618 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (617 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (618 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (654 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (655 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (675 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (675 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (675 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (675 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (530 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (532 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (532 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (532 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (592 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (593 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (592 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (545 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (545 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (546 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (546 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (547 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (548 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (546 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (546 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (547 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (547 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (545 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (546 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (546 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (546 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (603 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (805 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (803 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (805 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (820 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (832 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (601 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (600 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (600 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (601 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (599 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (600 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (601 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (591 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (592 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (592 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (592 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (572 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (573 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (573 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (578 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (577 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (578 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (635 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (635 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (635 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (635 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (610 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (610 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (545 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (546 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (546 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (545 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (545 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (544 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (547 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (633 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (633 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (633 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (634 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (633 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (632 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (622 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (624 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (624 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (621 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (623 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (607 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (606 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (607 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (608 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (606 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (607 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (608 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (605 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (608 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (606 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (605 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (606 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (607 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (606 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (597 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (597 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (597 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (597 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (597 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (597 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (605 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (605 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (605 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (605 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (603 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (606 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (605 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (604 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (603 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (639 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (640 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (639 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (637 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (675 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (675 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (674 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (667 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (668 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (666 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (665 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (773 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (770 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (772 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (773 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (770 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (771 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (768 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (767 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (773 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (773 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (771 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (693 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (709 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (833 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (833 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (616 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (612 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (611 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (612 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (615 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (614 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (613 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (583 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (585 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (585 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (583 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (584 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (586 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (585 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (584 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (584 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (584 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (584 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (584 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (583 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (583 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (585 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (585 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (584 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "WARNING: A masked sentence in a chunk was too long (594 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (593 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (596 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (595 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (590 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (588 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (589 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (561 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (560 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (561 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (561 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (561 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (561 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (562 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (560 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (561 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (561 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (561 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (552 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (552 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (551 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (552 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (552 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (554 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (552 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (552 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (552 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (553 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (552 tokens). Skipping this specific correction.\n",
      "WARNING: A masked sentence in a chunk was too long (551 tokens). Skipping this specific correction.\n",
      "FAILED RETURNING NONE\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Load Models and Run ---\n",
    "\n",
    "print(\"Loading the text correction model (this may take a moment)...\")\n",
    "corrector = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"roberta-base\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "spell = SpellChecker()\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "\n",
    "# --- 5. Run the Main Pipeline ---\n",
    "print(\"\\n--- Applying the FINAL cleaning pipeline ---\")\n",
    "dataset = dataset.map(\n",
    "    apply_cleaning_in_batch,\n",
    "    batched=True,\n",
    "    batch_size=1, # Process 8 full reviews at a time\n",
    "    fn_kwargs={'nlp_pipeline': corrector, 'spell_checker': spell, 'chunk_size' : 400, 'overlap':50}\n",
    ")\n",
    "print(\"Processing complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fad3080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Saving intermediate results (with any failures) ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a039ab47b16342dc868c6d56756cc5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating CSV from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 5. Save the Intermediate Results ---\n",
    "print(\"\\n--- Saving intermediate results (with any failures) ---\")\n",
    "dataset['train'].to_csv(f\"cleaned_{model_name}_reviews_with_failures.csv\", index=False)\n",
    "print(\"File saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a047c37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Recovery Process ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58295e4c87a246cfa95b8651d7688748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb4b71424a674bc5b92a46c1d7d97cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 62 failed examples to re-process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c18f06dcd24204b187e3deca861eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/62 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-processing complete. Now merging results.\n",
      "Final, fully cleaned file saved as 'cleaned_reviews_final.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 6. THE RECOVERY PROCESS ---\n",
    "\n",
    "print(\"\\n--- Starting Recovery Process ---\")\n",
    "# Load the dataset that contains the '__FAILED__' markers\n",
    "recovery_dataset = load_dataset(\"csv\", data_files=\"cleaned_roBERTa_reviews_with_failures.csv\")\n",
    "\n",
    "# Filter to get only the rows that failed\n",
    "failed_examples = recovery_dataset['train'].filter(\n",
    "    lambda example: example['Cleaned_text'] == \"__FAILED__\"\n",
    ")\n",
    "\n",
    "if len(failed_examples) > 0:\n",
    "    print(f\"Found {len(failed_examples)} failed examples to re-process.\")\n",
    "\n",
    "    # Re-run the pipeline on the small, failed dataset.\n",
    "    # Use a smaller batch_size or chunk_size for more safety.\n",
    "    reprocessed_failures = failed_examples.map(\n",
    "        apply_cleaning_in_batch,\n",
    "        batched=True,\n",
    "        batch_size=1, # Process 8 full reviews at a time\n",
    "        fn_kwargs={'nlp_pipeline': corrector, 'spell_checker': spell, 'chunk_size' : 200, 'overlap':30}\n",
    "    )\n",
    "\n",
    "    print(\"Re-processing complete. Now merging results.\")\n",
    "    # You would now merge these corrected results back into your main file.\n",
    "    # The easiest way is often with Pandas.\n",
    "    main_df = pd.read_csv(\"cleaned_roBERTa_reviews_with_failures.csv\")\n",
    "    reprocessed_df = reprocessed_failures.to_pandas()\n",
    "\n",
    "    # Create a dictionary from the reprocessed data for easy mapping\n",
    "    # We need a unique identifier; let's assume 'Full_text' is unique enough for this.\n",
    "    update_map = pd.Series(reprocessed_df['Cleaned_text'].values, index=reprocessed_df['Full_text']).to_dict()\n",
    "\n",
    "    # Update the main DataFrame\n",
    "    main_df['Cleaned_text'] = main_df.apply(\n",
    "        lambda row: update_map.get(row['Full_text'], row['Cleaned_text']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    main_df.to_csv(\"cleaned_roBERTa_reviews_final.csv\", index=False)\n",
    "    print(\"Final, fully cleaned file saved as 'cleaned_reviews_final.csv'\")\n",
    "\n",
    "else:\n",
    "    print(\"No failed examples found. Your initial run was successful!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93ec022f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3a6d9ce1124cd7b03deff97e07ac8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Applying the similarity calculation using batching ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ff9c3ca76c42d3945f3864ffa67d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dataset after adding the 'similarity_score' column ---\n",
      "               Author                                              Title  \\\n",
      "0        Marlowe, Sam  A satisfying treat of plain and simple storyte...   \n",
      "1                Null                                Seeing is believing   \n",
      "2       Craig, Amanda                   A spooky power to charm all ages   \n",
      "3        Mount, Harry              A lavatory read from the 16th century   \n",
      "4   Koning, Christina                                            Fiction   \n",
      "..                ...                                                ...   \n",
      "95               Null                                        Bestsellers   \n",
      "96               Null                                        Bestsellers   \n",
      "97               Null                                        Bestsellers   \n",
      "98       Davis, Clive                Who Wants to Be a Jazz Millionaire?   \n",
      "99   Jones, Nicolette            Fantasy Matches how our Brains are Made   \n",
      "\n",
      "   Publication         Date            Place  \\\n",
      "0    The Times  2008-Dec-26  London, England   \n",
      "1    The Times  2008-Dec-20  London, England   \n",
      "2    The Times  2008-Nov-01  London, England   \n",
      "3    The Times  2008-Nov-01  London, England   \n",
      "4    The Times  2008-Nov-01  London, England   \n",
      "..         ...          ...              ...   \n",
      "95   The Times  2004-Feb-07  London, England   \n",
      "96   The Times  2004-Jan-10  London, England   \n",
      "97   The Times  2003-Dec-13  London, England   \n",
      "98   The Times  2003-Apr-29  London, England   \n",
      "99   The Times  2003-Mar-26  London, England   \n",
      "\n",
      "                                            Full_text  \\\n",
      "0   First 'night-\\nA satisfying treat of plain an...   \n",
      "1   :Xsy% A- - ^ASL ;:.j/v>' .. *.* \\ \"* -'' \">...   \n",
      "2   A spooky power to charm t\\nMeeting Neil Gaima...   \n",
      "3   A lavatory read from the 16th century\\nEtiquet...   \n",
      "4   Fiction Christina Koning\\nMUDBOUND by Hillary ...   \n",
      "..                                                ...   \n",
      "95  BESTSELLERS .^ \\ ' J,, -: '. )'; ' * ' - . ; ...   \n",
      "96  BESTSELLERS ^ > ; : ' : y - ^ - ; , . . ' ^f\\j...   \n",
      "97  BESTSELLERS\\nHARDBACK FICTION 1 The Know 1 Mar...   \n",
      "98  'gM ^wtflr B^JB^^g^Ba liBlmBi^g J^^n ^fiRHB^BH...   \n",
      "99  \"FANTASY MATCHES HOW OUR BRAINS ARE MADE\"\\nDIA...   \n",
      "\n",
      "                                                  URL  \\\n",
      "0   https://link.gale.com/apps/doc/IF0503777543/TT...   \n",
      "1   https://link.gale.com/apps/doc/IF0503869968/TT...   \n",
      "2   https://link.gale.com/apps/doc/IF0503864618/TT...   \n",
      "3   https://link.gale.com/apps/doc/IF0503864628/TT...   \n",
      "4   https://link.gale.com/apps/doc/IF0503864637/TT...   \n",
      "..                                                ...   \n",
      "95  https://link.gale.com/apps/doc/IF0501668453/TT...   \n",
      "96  https://link.gale.com/apps/doc/IF0502539096/TT...   \n",
      "97  https://link.gale.com/apps/doc/IF0501656831/TT...   \n",
      "98  https://link.gale.com/apps/doc/IF0501582524/TT...   \n",
      "99  https://link.gale.com/apps/doc/IF0502499137/TT...   \n",
      "\n",
      "                                         Cleaned_text  similarity_score  \n",
      "0   First night- A satisfying treat of plain and s...          0.989102  \n",
      "1   Xsy A-- ASL. jv...-? ti-, 4l- a1..? i s r. fc ...          0.878828  \n",
      "2   A spooky power to charm t Meeting Neil Gaiman ...          0.963213  \n",
      "3   A lavatory read from the 16th century Etiquett...          0.961917  \n",
      "4   Fiction Christina Koning MUDBOUND by Hillary J...          0.981465  \n",
      "..                                                ...               ...  \n",
      "95  BESTSELLERS. J,,-.-..,- hardbackfiction-. W-,-...          0.965698  \n",
      "96  BESTSELLERS y--,.. fj. C- Vg v.. HARDBACK FICT...          0.945870  \n",
      "97  BESTSELLERS HARDBACK FICTION 1 The Know 1 Mart...          1.000000  \n",
      "98  gM wtflr BJBgBa liBlmBig Jn fiRHBBH iQ Wb mB h...          0.511765  \n",
      "99  FANTASY MATCHES HOW OUR BRAINS ARE MADE DIANA ...          0.827174  \n",
      "\n",
      "[100 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load the dataset with cleaned text into a dataframe ---\n",
    "dataset = load_dataset(\"csv\", data_files=\"cleaned_roBERTa_reviews_final.csv\")\n",
    "\n",
    "# --- 2. Define the SequenceMatcher comparison function ---\n",
    "def calculate_similarity(text_a: str, text_b: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculates a similarity ratio between two strings using SequenceMatcher.\n",
    "    Returns a float between 0.0 (totally different) and 1.0 (identical).\n",
    "    \"\"\"\n",
    "    # Ensure inputs are strings to avoid errors\n",
    "    if not isinstance(text_a, str) or not isinstance(text_b, str):\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate and return the similarity ratio\n",
    "    return difflib.SequenceMatcher(None, text_a, text_b).ratio()\n",
    "\n",
    "# --- 3. Define the Mapping Function for Batch Processing ---\n",
    "def add_similarity_in_batch(examples):\n",
    "    \"\"\"\n",
    "    This function is designed for .map(batched=True).\n",
    "    'examples' is a dictionary where each value is a LIST of items.\n",
    "    \"\"\"\n",
    "    # Use a list comprehension with zip to efficiently process the batch.\n",
    "    # This pairs up each 'Full_text' with its corresponding 'Cleaned_text'.\n",
    "    similarity_scores = [\n",
    "        calculate_similarity(pre_clean_for_model(original), cleaned)\n",
    "        for original, cleaned in zip(examples['Full_text'], examples['Cleaned_text'])\n",
    "    ]\n",
    "    \n",
    "    # Return a dictionary with the new column. The value must be a list.\n",
    "    return {'similarity_score': similarity_scores}\n",
    "\n",
    "\n",
    "# --- 4. Apply the Mapping ---\n",
    "print(\"--- Applying the similarity calculation using batching ---\")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    add_similarity_in_batch,\n",
    "    batched=True,\n",
    "    batch_size=500  # For CPU tasks, a larger batch size is fine\n",
    ")\n",
    "\n",
    "print(\"\\n--- Dataset after adding the 'similarity_score' column ---\")\n",
    "print(dataset['train'].to_pandas())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3b5a5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  0.,  0.,  0.,  1.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  2.,\n",
       "         0.,  2.,  0.,  0.,  1.,  0.,  0.,  0.,  1.,  1.,  0.,  2.,  6.,\n",
       "         1.,  7.,  3.,  4.,  6.,  2.,  1.,  9.,  9., 19., 17.]),\n",
       " array([0.45006542, 0.46106411, 0.4720628 , 0.48306149, 0.49406018,\n",
       "        0.50505887, 0.51605757, 0.52705626, 0.53805495, 0.54905364,\n",
       "        0.56005233, 0.57105102, 0.58204972, 0.59304841, 0.6040471 ,\n",
       "        0.61504579, 0.62604448, 0.63704317, 0.64804187, 0.65904056,\n",
       "        0.67003925, 0.68103794, 0.69203663, 0.70303532, 0.71403402,\n",
       "        0.72503271, 0.7360314 , 0.74703009, 0.75802878, 0.76902747,\n",
       "        0.78002617, 0.79102486, 0.80202355, 0.81302224, 0.82402093,\n",
       "        0.83501962, 0.84601832, 0.85701701, 0.8680157 , 0.87901439,\n",
       "        0.89001308, 0.90101177, 0.91201047, 0.92300916, 0.93400785,\n",
       "        0.94500654, 0.95600523, 0.96700392, 0.97800262, 0.98900131,\n",
       "        1.        ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(dataset['train']['similarity_score'], bins=50, color='skyblue', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae286cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 95 reviews with a similarity score below 0.05 to inspect.\n"
     ]
    }
   ],
   "source": [
    "df_sorted = dataset['train'].to_pandas().sort_values(by='similarity_score')\n",
    "# Filter for the most heavily altered reviews\n",
    "#suspicious_reviews = df_sorted[df_sorted['similarity_score'].between(0.55, 0.58, inclusive='neither')]\n",
    "suspicious_reviews = df_sorted[df_sorted['similarity_score'] <1]\n",
    "\n",
    "print(f\"Found {len(suspicious_reviews)} reviews with a similarity score below 0.05 to inspect.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "972777b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- The Side-by-Side Pretty Print Function ---\n",
    "def pretty_print_side_by_side(review_series, total_width=120):\n",
    "    \"\"\"\n",
    "    Prints a side-by-side comparison of the pre-cleaned original text and\n",
    "    the final roBERTa-restored text for a single review.\n",
    "\n",
    "    Args:\n",
    "        review_series (pd.Series): A single row from your DataFrame.\n",
    "        total_width (int): The total width of the output in characters.\n",
    "    \"\"\"\n",
    "    # Calculate the width for each text column\n",
    "    divider = \"   |   \"\n",
    "    col_width = (total_width - len(divider)) // 2\n",
    "\n",
    "    # Get the two versions of the text\n",
    "    original_pre_cleaned = pre_clean_for_model(review_series['Full_text'])\n",
    "    roBERTa_cleaned = review_series['Cleaned_text']\n",
    "    \n",
    "    # Wrap the text in each column into lists of lines\n",
    "    original_lines = textwrap.wrap(original_pre_cleaned, width=col_width)\n",
    "    cleaned_lines = textwrap.wrap(roBERTa_cleaned, width=col_width)\n",
    "    \n",
    "    # --- Start Printing ---\n",
    "    print(\"=\" * total_width)\n",
    "    # Use .get() to avoid an error if 'similarity_score' doesn't exist\n",
    "    score = review_series.get('similarity_score', 'N/A')\n",
    "    if isinstance(score, float):\n",
    "        score = f\"{score:.4f}\"\n",
    "    print(f\"Similarity Score: {score}\".center(total_width))\n",
    "    print(\"-\" * total_width)\n",
    "    \n",
    "    # Print headers\n",
    "    header_original = \"Pre-Cleaned Original\".center(col_width)\n",
    "    header_cleaned = \"roBERTa Restored Text\".center(col_width)\n",
    "    print(f\"{header_original}{divider}{header_cleaned}\")\n",
    "    print(\"-\" * total_width)\n",
    "\n",
    "    # Print the lines side-by-side\n",
    "    max_lines = max(len(original_lines), len(cleaned_lines))\n",
    "    for i in range(max_lines):\n",
    "        # Get the line for each side, or an empty string if one side is shorter\n",
    "        left_line = original_lines[i] if i < len(original_lines) else \"\"\n",
    "        right_line = cleaned_lines[i] if i < len(cleaned_lines) else \"\"\n",
    "        \n",
    "        # Print the formatted line with padding\n",
    "        print(f\"{left_line:<{col_width}}{divider}{right_line:<{col_width}}\")\n",
    "        \n",
    "    print(\"=\" * total_width + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28c98586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "                                                Similarity Score: 0.5118                                                \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "                  Pre-Cleaned Original                     |                    roBERTa Restored Text                  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "gM wtflr BJBgBa liBlmBig Jn fiRHBBH iQ Wb mB hBI wBbmB     |   gM wtflr BJBgBa liBlmBig Jn fiRHBBH iQ Wb mB hBI wBbmB  \n",
      "BHbR An SO IS IT ALL HYPE? There have been so many bogus   |   BHbR An SO IS IT ALL HYPE? There have been so many bogus\n",
      "sto - r ies about big-money advanc - es to unknown         |   market- r uled about big- money and- es to unknown      \n",
      "artists that these deals should perhaps be measured in a   |   artists that these deals should perhaps be measured in a\n",
      "new unit of cur - rency . The Magnus would be named        |   new unit of cur- master. The Magnus would be named after\n",
      "after Magnus Mills, the bus driver-turned novelist who     |   Magnus Mills, the bus driver- turned novelist who was   \n",
      "was supposed to have been handed his own personal crock    |   supposed to have been handed his own personal crock of  \n",
      "of gold in exchange for his debut book. After all the hy   |   gold in exchange for his debut book. After all the self-\n",
      "- perventilating had died down, the alleged fortune        |   be had died down, the alleged fortune turned out to be  \n",
      "turned out to be rather less than he could have earned     |   rather less than he could have earned steering a Route- \n",
      "steering a Route - master along Oxford Street. So when     |   master along Oxford Street. So when news broke late last\n",
      "news broke late last week that the 23-year-old singer-     |   week that the 23- year- old singer- pianist Jamie Cullum\n",
      "pianist Jamie Cullum HE IS VIRTUALLY UNKNOWN, BUT SINGER   |   HE IS VIRTUALLY UNKNOWN, BUT SINGER JAMIE CULLUM HAS    \n",
      "JAMIE CULLUM HAS JUST SIGNED A 1 MILLION DEAL. CAN HE BE   |   JUST SIGNED A 1 MILLION DEAL. CAN HE BE WORTH IT, ASKS  \n",
      "WORTH IT, ASKS CLIVE DAVIS had signed a million-pound      |   CLIVE DAVIS had signed a million- pound deal with       \n",
      "deal with Universal Music you could be forgiven for        |   Universal Music you could be forgiven for assuming that \n",
      "assuming that somebody was indulging in more speculation   |   somebody was indulging in more speculation on the Magnus\n",
      "on the Magnus market. After all, Cul - lum is a jazz       |   market. After all, Cul- lum is a jazz musician, and jazz\n",
      "musician, and jazz musicians are more accus - tomed to     |   musicians are more so- but to seeing their names printed\n",
      "seeing their names printed on social security cheques      |   on social security on anything with lots of noughts.    \n",
      "than on anything with lots of noughts. Hence Ronnie        |   Hence Ronnie Scotts old joke how do you make a million  \n",
      "Scotts old joke how do you make a million from jazz?       |   from jazz? Answer start with two million. But this time \n",
      "Answer start with two million. But this time the deal is   |   the deal is genuine. Cullum will receive slightly more  \n",
      "genuine. Cullum will receive slightly more than a          |   than a million in return for four albums, with the first\n",
      "million in return for four albums, with the first due to   |   due to be released in the autumn. Universal is the      \n",
      "be released in the autumn . Universal is the parent com    |   parent com- name of Verve, home to the enormously       \n",
      "- pany of Verve, home to the enormously successful Diana   |   successful Diana Krall, so it does not take a clair-    \n",
      "Krall, so it does not take a clair - voyant to see where   |   music to see where Cullum may be headed. Dickon Stainer,\n",
      "Cullum may be headed. Dickon Stainer, the Universal        |   the Universal ist- of who has had a hand in the rise of \n",
      "execu - tive who has had a hand in the rise of             |   classical- lite performers such as Russell Watson and   \n",
      "classical-lite performers such as Russell Watson and       |   girlie string quartet Bond, in- forms me that Cullum    \n",
      "girlie string quartet Bond, in - forms me that Cullum      |   will be taking his band into the studio in the next     \n",
      "will be taking his band into the studio in the next        |   couple of weeks to lay down some tracks. He has a clear \n",
      "couple of weeks to lay down some tracks. He has a clear    |   idea of what he wants, Stainer says. We want to keep him\n",
      "idea of what he wants, Stainer says. We want to keep him   |   true to himself. Other major labels, and- ing Sony, were\n",
      "true to himself.Other major labels, includ - ing Sony,     |   also on the trail of Cullum, who last year used his own \n",
      "were also on the trail of Cullum, who last year used his   |   money to release an acclaimed album, Pointless          \n",
      "own money to release an acclaimed album, Pointless         |   Nostalgic, mixing Harry Con- nick- style swing with some\n",
      "Nostalgic , mixing Harry Con - nick - style swing with     |   in- sp i r ed pop- music originals. But why were        \n",
      "some in - sp i r ed pop-flavoured originals . But why      |   Universal prepared to pay so much? It was desperation,  \n",
      "were Universal prepared to pay so much? It was             |   Stainer cheerfully explains. Wed have done anything to  \n",
      "desperation, Stainer cheerfully explains. Wed have done    |   sign him. Wed have bungee- jumped off a cliff, if       \n",
      "anything to sign him. Wed have bungee - jumped off a       |   necessary. Hes the most talented in- if st ever come    \n",
      "cliff, if necessary. Hes the most talented musi - cian     |   across. Viewers who saw Cullum make his TV debut on     \n",
      "weve ever come across. Viewers who saw Cullum make his     |   Michael Parkinsons show on Saturday may ask themselves  \n",
      "TV debut on Michael Parkinsons show on Saturday may ask    |   if the record moguls had suffered a rush of blood. The  \n",
      "themselves if the record moguls had suffered a rush of     |   choice of song, Youre Nobody Til Some- b o d y Loves    \n",
      "blood. The choice of song, Youre Nobody Til Some - b o d   |   You, was, after all, a little tame, and the mid- Atlan- \n",
      "y Loves You, was, after all, a little tame, and the mid    |   tic vocals had Connick stamped all over them. Why all   \n",
      "- Atlan - tic vocals had Connick stamped all over them.    |   the fuss? For one thing, though, Cul- l um was shrewdly \n",
      "Why all the fuss? For one thing, though , Cul - l um was   |   tapping into the same audience that has ac- wh a taste  \n",
      "shrewdly tapping into the same audience that has ac -      |   for s bestselling swing band theatrics. And even in that\n",
      "quired a taste for Robbie Wil - liams s bestselling        |   brief appearance on Saturday, it was clear that the     \n",
      "swing band theatrics. And even in that brief appearance    |   diminutive pianist possesses enormous charisma. Where   \n",
      "on Saturday, it was clear that the diminutive pianist      |   Williamss Swing When Youre Winning of- and nothing more \n",
      "possesses enormous charisma . Where Williamss Swing When   |   than reheat- ed Rat Pack on, Cul- lem is sculpting a    \n",
      "Youre Winning of - fers nothing more than reheat - ed      |   genuinely original approach that blends past and        \n",
      "Rat Pack fingersnaps, Cul - lum is sculpting a genuinely   |   present. Having gigged in rock bands too, he is as happy\n",
      "original approach that blends past and present. Having     |   reinventing a Radio- head tune as he is delving into    \n",
      "gigged in rock bands too, he is as happy reinventing a     |   Sinatras greatest hits. HES THE MOST TALENTED MUSICIAN  \n",
      "Radio - head tune as he is delving into Sinatras           |   WEVE COME ACROSS The Connick comparisons are worth      \n",
      "greatest hits. HES THE MOST TALENTED MUSICIAN WEVE COME    |   pondering too. Cul- he is a grittier performer. But the \n",
      "ACROSS The Connick comparisons are worth pondering too.    |   first time I saw him play live last summer, I could not \n",
      "Cul - lum is a grittier performer. But the first time I    |   help recalling the evening, al- most a decade and a half\n",
      "saw him play live last summer, I could not help            |   ago, when Connick then all- known here gave an aston- re\n",
      "recalling the evening, al - most a decade and a half       |   assured London debut at the Dominion. Jazzniks were slow\n",
      "ago, when Connick then un - known here gave an aston -     |   to re- and then, partly because commercial success      \n",
      "ishingly assured London debut at the Dominion. Jazzniks    |   always arouses suspicion, partly be- looks filled so    \n",
      "were slow to re - spond then, partly because commercial    |   many column inches. It took several years be- fore the  \n",
      "success always arouses suspicion , partly be - cause       |   critical establishment began to take him seriously.     \n",
      "Connicks matinee idol looks filled so many column          |   Interestingly enough, Diana Krall was no overnight      \n",
      "inches. It took several years be - fore the critical       |   success with them either. She was, per- chance, too     \n",
      "establishment began to take him seriously. Interestingly   |   blonde for her own good. Cullum may face be- lar        \n",
      "enough, Diana Krall was no overnight success with them     |   resistance at first, but only the most churlish soul    \n",
      "either. She was, per - haps , too blonde for her own       |   would fail to acknowledge that he is a truly gifted     \n",
      "good. Cullum may face simi - lar resistance at first,      |   figure, part show- man, part unreconstructed figure.    \n",
      "but only the most churlish soul would fail to              |   Like Connick who was often portrayed as in- a very cocky\n",
      "acknowledge that he is a truly gifted figure, part show    |   he is aware of how much work he still needs to do.      \n",
      "- man , part unreconstructed jazzer. Like Connick who      |   Anyone who has inter- viewed him will have been struck  \n",
      "was often portrayed as unbear - a bly cocky he is aware    |   by how openly he talks of his desire to improve his     \n",
      "of how much work he still needs to do. Anyone who has      |   piano technique so that he can express the ideas        \n",
      "inter - viewed him will have been struck by how openly     |   bubbling in his head. Will he make it in Ameri- ca?     \n",
      "he talks of his desire to improve his piano technique so   |   October will offer the first test. That month he has a  \n",
      "that he can express the ideas bubbling in his head. Will   |   is- st at the Algonquins Oak Room in con- according to  \n",
      "he make it in Ameri - ca ? October will offer the first    |   Robbie Williams, who is about as cosmopolitan as Shakin \n",
      "test. That month he has a resi - dency at the Algonquins   |   Stevens, he has the po- asy to cross the water. Word is \n",
      "Oak Room in New York. In con - trast to Robbie Williams,   |   slowly circulating in Manhattan, according to the       \n",
      "who is about as cosmopolitan as Shakin Stevens, he has     |   leading critic Will Friedwald. I enjoyed the album, he  \n",
      "the po - tential to cross the water. Word is slowly        |   says. It was very well pro- life, with a very good band.\n",
      "circulating in Manhattan, according to the leading         |   I con quite decide wheth- er he was the British Connick \n",
      "critic Will Friedwald. I enjoyed the album, he says. It    |   or the male Krall. I like him lots better than Connick  \n",
      "was very well pro - duced , with a very good band. I       |   whom I cant stand but not as much as Krall. It will be  \n",
      "couldnt quite decide wheth - er he was the British         |   fascinating to see how the young hopeful fares. It is   \n",
      "Connick or the male Krall. I like him lots better than     |   worth bearing in mind that the record industry has never\n",
      "Connick whom I cant stand but not as much as Krall. It     |   quite got the best out of Connick, one of those restless\n",
      "will be fascinating to see how the young hopeful fares.    |   figures who always seem more alive on the bandstand than\n",
      "It is worth bearing in mind that the record industry has   |   in the studio. Nor will it be easy to compete with the  \n",
      "never quite got the best out of Connick, one of those      |   po- and Diana Krall. On the other hand, the introverted \n",
      "restless figures who always seem more alive on the         |   Canadi- an singer has scored her big- gest commercial   \n",
      "bandstand than in the studio. Nor will it be easy to       |   string- laden pro- business values. Cullum has more than\n",
      "compete with the impecca - ble Diana Krall. On the other   |   enough personality to achieve stardom without smoothing \n",
      "hand, the introverted Canadi - an singer has scored her    |   down the rough edges. Something tells me there will be  \n",
      "big - gest commercial successes with glossy, string-       |   many more than in the post. Swinging on a star Jamie    \n",
      "laden pro - duction values. Cullum has more than enough    |   Cullum is shrewdly tapping into a market Robbie Williams\n",
      "personality to achieve stardom without smoothing down      |   has opened up                                           \n",
      "the rough edges. Something tells me there will be many     |                                                           \n",
      "more cheques in the post. Swinging on a star Jamie         |                                                           \n",
      "Cullum is shrewdly tapping into a market Robbie Williams   |                                                           \n",
      "has opened up                                              |                                                           \n",
      "========================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_side_by_side(suspicious_reviews.iloc[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "andreas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
